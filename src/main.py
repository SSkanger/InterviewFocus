# src/main.py - é¢è¯•åŠ©æ‰‹v0.2
import cv2
import pyttsx3
import numpy as np
import time
from datetime import datetime

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from camera_utils import CameraManager
from voice_utils import VoiceFeedback
from ui_manager import UIManager

# å¯¼å…¥æ£€æµ‹æ¨¡å—
try:
    from detection.face_detector import FaceDetector
    from detection.gaze_detector import GazeDetector
    from detection.pose_detector import PoseDetector
    from detection.gesture_detector import GestureDetector
    DETECTION_MODULES_AVAILABLE = True
    print("âœ… æ£€æµ‹æ¨¡å—åŠ è½½æˆåŠŸ")
except ImportError as e:
    DETECTION_MODULES_AVAILABLE = False
    print(f"âš ï¸ æ£€æµ‹æ¨¡å—åŠ è½½å¤±è´¥: {e}")
    print("å°†ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿è¡Œ")

class InterviewCoachV2:
    """é¢è¯•åŠ©æ‰‹ - ç‰ˆæœ¬2.0ï¼ˆé›†æˆæ£€æµ‹åŠŸèƒ½ï¼‰"""

    def __init__(self, use_ui=True):
        # åˆå§‹åŒ–æ‘„åƒå¤´ç®¡ç†å™¨
        self.camera = CameraManager(camera_id=0, resolution=(640, 480), fps=30)
        
        # åˆå§‹åŒ–è¯­éŸ³åé¦ˆç³»ç»Ÿ
        self.voice = VoiceFeedback(rate=160, volume=0.8)
        # ä¿å­˜è¯­éŸ³å¼•æ“çš„å¼•ç”¨ï¼Œæ–¹ä¾¿ç›´æ¥ä½¿ç”¨
        self.engine = self.voice.engine
        
        # åˆå§‹åŒ–UIç®¡ç†å™¨ - ä»…åœ¨éWebç¯å¢ƒä¸‹ä½¿ç”¨
        self.ui = None
        if use_ui:
            # åˆå§‹åŒ–UIç®¡ç†å™¨ - çª—å£å°ºå¯¸ä¸æ‘„åƒå¤´åˆ†è¾¨ç‡åŒ¹é…
            self.ui = UIManager(window_name="Interview Coach", window_size=(640, 480))
        
        # åˆå§‹åŒ–æ£€æµ‹å™¨ï¼ˆå¦‚æœæ¨¡å—å¯ç”¨ï¼‰
        self.detection_enabled = DETECTION_MODULES_AVAILABLE
        if self.detection_enabled:
            self.face_detector = FaceDetector()
            self.gaze_detector = GazeDetector()
            self.pose_detector = PoseDetector()
            self.gesture_detector = GestureDetector()
            print("âœ… æ‰€æœ‰æ£€æµ‹å™¨å·²åˆå§‹åŒ–")
        else:
            print("âš ï¸ æ£€æµ‹å™¨ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")

        # çŠ¶æ€å˜é‡
        self.is_running = False
        self.start_time = None
        self.frame_count = 0
        self.last_speak_time = 0
        
        # æ£€æµ‹çŠ¶æ€
        self.face_detected = False
        self.gaze_status = "æ­£å¸¸"
        self.pose_status = "æ­£å¸¸"
        self.gesture_status = "æ— "
        self.attention_score = 100.0  # åˆå§‹åˆ†æ•°è®¾ä¸ºæ»¡åˆ†
        
        # ç»Ÿè®¡æ•°æ®
        self.gaze_away_count = 0
        self.pose_issue_count = 0
        self.gesture_count = 0

        print("âœ… é¢è¯•åŠ©æ‰‹v2.0å·²åˆå§‹åŒ–")
        print("Tips: Press 's' to start/stop, 'q' to exit, 't' to test voice")

    def speak(self, text, urgent=False):
        """è¯­éŸ³è¾“å‡ºï¼ˆå¸¦å†·å´æ—¶é—´ï¼‰"""
        current_time = datetime.now().timestamp()

        # å†·å´æ—¶é—´ï¼šç´§æ€¥æç¤º2ç§’ï¼Œæ™®é€šæç¤º4ç§’
        cooldown = 2.0 if urgent else 4.0

        if current_time - self.last_speak_time > cooldown:
            print(f"ğŸ”Š è¯­éŸ³æç¤º: {text}")
            self.engine.say(text)
            self.engine.runAndWait()
            self.last_speak_time = current_time
            return True
        return False

    def draw_ui(self, frame):
        """ç»˜åˆ¶UIç•Œé¢
        
        Args:
            frame: è§†é¢‘å¸§
            
        Returns:
            å¸¦UIçš„è§†é¢‘å¸§
        """
        # å¦‚æœUIæœªåˆå§‹åŒ–ï¼Œç›´æ¥è¿”å›åŸå§‹å¸§
        if not self.ui:
            return frame
            
        # ç»˜åˆ¶é¡¶éƒ¨çŠ¶æ€æ 
        frame = self.ui.draw_top_bar(frame)
        
        # ç»˜åˆ¶å³ä¾§ä¿¡æ¯é¢æ¿
        status_info = {
            'status': 'æ­£å¸¸' if self.attention_score >= 70 else 'æ³¨æ„åŠ›ä¸é›†ä¸­',
            'attention_score': int(self.attention_score),
            'gaze_direction': self.gaze_status,
            'posture': self.pose_status,
            'gesture': self.gesture_status,
            'look_away_count': self.gaze_away_count,
            'bad_posture_count': self.pose_issue_count,
            'gesture_count': self.gesture_count
        }
        frame = self.ui.draw_side_panel(frame, status_info)
        
        # ç»˜åˆ¶åº•éƒ¨ä¿¡æ¯æ 
        feedback_text = self.voice.get_latest_feedback() or "ç³»ç»Ÿè¿è¡Œä¸­..."
        frame = self.ui.draw_bottom_bar(frame, feedback_text)
        
        # ç»˜åˆ¶æ³¨æ„åŠ›ä»ªè¡¨ç›˜
        frame = self.ui.draw_attention_meter(frame, self.attention_score)
        
        # å¦‚æœæ£€æµ‹åˆ°é¢éƒ¨ï¼Œç»˜åˆ¶å…³é”®ç‚¹å’Œè§†çº¿æ–¹å‘
        if self.face_detected and self.detection_enabled:
            # è·å–é¢éƒ¨å…³é”®ç‚¹
            has_face, landmarks, _ = self.face_detector.detect(frame)
            if has_face and landmarks:
                frame = self.ui.draw_face_landmarks(frame, landmarks)
            
            # è·å–è§†çº¿æ£€æµ‹ç»“æœ
            is_looking, offset_ratio, annotated_frame = self.gaze_detector.detect_gaze(frame)
            if is_looking is not None:
                # ä½¿ç”¨å¸¦æ ‡æ³¨çš„å›¾åƒ
                frame = annotated_frame
        
        # æ·»åŠ æ—¶é—´æˆ³
        frame = self.ui.add_timestamp(frame)
        
        # å¦‚æœæ³¨æ„åŠ›åˆ†æ•°è¿‡ä½ï¼Œæ·»åŠ è­¦å‘Š
        if self.attention_score < 50:
            frame = self.ui.add_warning(frame, "æ³¨æ„åŠ›ä¸é›†ä¸­ï¼Œè¯·é›†ä¸­ç²¾ç¥ï¼")
        
        return frame

    def run(self):
        """ä¸»å¾ªç¯"""
        print("â–¶ï¸ Starting main loop...")
        
        # æ‰“å¼€æ‘„åƒå¤´
        if not self.camera.open():
            print("âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
            return
        
        # åˆ›å»ºUIçª—å£
        self.ui.create_window()
        
        # ä¸»å¾ªç¯
        while True:
            # è¯»å–æ‘„åƒå¤´å¸§
            ret, frame = self.camera.read_frame()
            if not ret:
                print("âŒ æ— æ³•è¯»å–æ‘„åƒå¤´ç”»é¢")
                break
            
            self.frame_count += 1
            
            # å¦‚æœæ­£åœ¨è¿è¡Œï¼Œè¿›è¡Œæ£€æµ‹å’Œæ›´æ–°
            if self.is_running:
                self._update_detection(frame)
                self._update_feedback()
            
            # è·å–ä¼šè¯æ—¶é—´å’ŒFPS
            session_time = 0
            fps = self.camera.fps_actual
            if self.start_time:
                session_time = (datetime.now() - self.start_time).total_seconds()
            
            # ç»˜åˆ¶UI
            frame = self.draw_ui(frame)
            
            # æ˜¾ç¤ºç”»é¢
            cv2.imshow(self.ui.window_name, frame)
            
            # é”®ç›˜ç›‘å¬
            key = cv2.waitKey(1) & 0xFF
            
            # 's'é”®ï¼šå¼€å§‹/åœæ­¢
            if key == ord('s'):
                self.is_running = not self.is_running
                if self.is_running:
                    self.start_time = datetime.now()
                    self._reset_statistics()
                    self.voice.start_session()
                    print("âºï¸ Started recording...")
                else:
                    self.voice.end_session()
                    print("â¹ï¸ Stopped recording")
            
            # 't'é”®ï¼šæµ‹è¯•è¯­éŸ³
            elif key == ord('t'):
                self.voice.test_voice()
            
            # 'q'é”®ï¼šé€€å‡º
            elif key == ord('q'):
                self.voice.end_session()
                break
        
        # æ¸…ç†èµ„æº
        self.camera.close()
        self.ui.destroy_window()
        print("ğŸ‘‹ Program exited")
    
    def _update_detection(self, frame):
        """æ›´æ–°æ£€æµ‹ç»“æœ
        
        Args:
            frame: å›¾åƒå¸§
        """
        if not self.detection_enabled:
            # æ¨¡æ‹Ÿæ£€æµ‹æ•°æ®
            self._simulate_detection()
            return
        
        # é¢éƒ¨æ£€æµ‹ - ç¦ç”¨ç»˜åˆ¶ä»¥æé«˜æ€§èƒ½
        has_face, landmarks, _ = self.face_detector.detect(frame, draw_annotations=False)
        self.face_detected = has_face
        
        # æ£€æŸ¥é¢éƒ¨æ£€æµ‹ç»“æœå’Œå…³é”®ç‚¹
        if not self.face_detected or landmarks is None:
            # æ²¡æœ‰æ£€æµ‹åˆ°é¢éƒ¨æˆ–å…³é”®ç‚¹æ— æ•ˆï¼Œé‡ç½®å…¶ä»–æ£€æµ‹çŠ¶æ€
            self.gaze_status = "æœªæ£€æµ‹åˆ°é¢éƒ¨"
            self.pose_status = "æœªæ£€æµ‹åˆ°é¢éƒ¨"
            self.gesture_status = "æœªæ£€æµ‹åˆ°é¢éƒ¨"
            self.attention_score = max(0, self.attention_score - 2)
            return
        
        try:
            # è§†çº¿æ£€æµ‹ï¼ˆéœ€è¦æœ‰æ•ˆçš„é¢éƒ¨å…³é”®ç‚¹ï¼‰- ç¦ç”¨ç»˜åˆ¶
            is_looking, offset_ratio, _ = self.gaze_detector.detect_gaze(frame, draw_annotations=False)
            self.gaze_status = self.gaze_detector.get_gaze_status_text(is_looking, offset_ratio)
            if self.gaze_status != "æ­£å¸¸":
                self.gaze_away_count += 1
        except Exception as e:
            print(f"è§†çº¿æ£€æµ‹å¤±è´¥: {e}")
            self.gaze_status = "æ£€æµ‹å¤±è´¥"
        
        try:
            # å§¿æ€æ£€æµ‹ - ç¦ç”¨ç»˜åˆ¶
            pose_status, pose_angle, _ = self.pose_detector.detect_pose(frame, draw_annotations=False)
            self.pose_status = self.pose_detector.get_pose_status_text(pose_status)
            if self.pose_status != "è‰¯å¥½":
                self.pose_issue_count += 1
        except Exception as e:
            print(f"å§¿æ€æ£€æµ‹å¤±è´¥: {e}")
            self.pose_status = "æ£€æµ‹å¤±è´¥"
        
        try:
            # æ‰‹åŠ¿æ£€æµ‹ - ç¦ç”¨ç»˜åˆ¶
            gesture_type, confidence, _ = self.gesture_detector.detect_gestures(frame, draw_annotations=False)
            self.gesture_status = self.gesture_detector.get_gesture_status_text(gesture_type, confidence)
            if self.gesture_status != "æ— å°åŠ¨ä½œ":
                self.gesture_count += 1
        except Exception as e:
            print(f"æ‰‹åŠ¿æ£€æµ‹å¤±è´¥: {e}")
            self.gesture_status = "æ£€æµ‹å¤±è´¥"
        
        # è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°
        self._calculate_attention_score()
    
    def _simulate_detection(self):
        """æ¨¡æ‹Ÿæ£€æµ‹ç»“æœï¼ˆå½“æ£€æµ‹æ¨¡å—ä¸å¯ç”¨æ—¶ï¼‰"""
        import random
        
        # åªåœ¨æ¯30å¸§æ›´æ–°ä¸€æ¬¡æ¨¡æ‹Ÿæ•°æ®ï¼ˆçº¦1ç§’æ›´æ–°ä¸€æ¬¡ï¼Œå‡è®¾30fpsï¼‰
        if self.frame_count % 30 != 0:
            return
        
        # æ¨¡æ‹Ÿé¢éƒ¨æ£€æµ‹ï¼ˆ95%æ¦‚ç‡æˆåŠŸï¼‰
        self.face_detected = random.random() < 0.95
        
        if not self.face_detected:
            self.gaze_status = "æœªæ£€æµ‹åˆ°é¢éƒ¨"
            self.pose_status = "æœªæ£€æµ‹åˆ°é¢éƒ¨"
            self.gesture_status = "æœªæ£€æµ‹åˆ°é¢éƒ¨"
            self.attention_score = max(0, self.attention_score - random.uniform(10, 20))
            return
        
        # æ¨¡æ‹Ÿè§†çº¿æ£€æµ‹ï¼ˆ80%æ¦‚ç‡æ­£å¸¸ï¼‰
        if random.random() < 0.8:
            self.gaze_status = "æ­£å¸¸"
        else:
            self.gaze_status = "è§†çº¿åç¦»"
            self.gaze_away_count += 1
        
        # æ¨¡æ‹Ÿå§¿æ€æ£€æµ‹ï¼ˆ85%æ¦‚ç‡æ­£å¸¸ï¼‰
        if random.random() < 0.85:
            self.pose_status = "è‰¯å¥½"
        else:
            self.pose_status = random.choice(["âš ï¸ è¯·å‹¿é¢‘ç¹æŠ¬å¤´", "âš ï¸ è¯·ä¿æŒæŠ¬å¤´æŒºèƒ¸", "âš ï¸ è¯·ä¿æŒå¤´éƒ¨æ­£ç›´", "âš ï¸ è¯·ä¿æŒé¢å‘æ‘„åƒå¤´"])
            self.pose_issue_count += 1
        
        # æ¨¡æ‹Ÿæ‰‹åŠ¿æ£€æµ‹ï¼ˆ90%æ¦‚ç‡æ— å°åŠ¨ä½œï¼‰
        if random.random() < 0.9:
            self.gesture_status = "æ— å°åŠ¨ä½œ"
        else:
            self.gesture_status = random.choice(["âš ï¸ è¯·é¿å…æ‘¸è„¸", "âš ï¸ è¯·é¿å…æ‘¸ä¸‹å·´", "âš ï¸ è¯·é¿å…æ‘¸å¤´å‘", "âš ï¸ è¯·é¿å…æ‰˜è…®"])
            self.gesture_count += 1
        
        # è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°
        self._calculate_attention_score()
    
    def _calculate_attention_score(self):
        """è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°"""
        # åŸºç¡€åˆ†æ•°
        score = 100.0  # ä»æ»¡åˆ†å¼€å§‹ï¼Œæ ¹æ®é—®é¢˜æ‰£åˆ†
        
        # æ ¹æ®æ£€æµ‹ç»“æœè°ƒæ•´åˆ†æ•°
        if not self.face_detected:
            score -= 40  # æ²¡æœ‰æ£€æµ‹åˆ°é¢éƒ¨æ‰£åˆ†æ›´å¤š
        else:
            if self.gaze_status != "æ­£å¸¸":
                score -= 25  # è§†çº¿ä¸æ­£å¸¸æ‰£åˆ†è¾ƒå¤š
            if self.pose_status != "è‰¯å¥½":
                score -= 20  # å§¿æ€ä¸å¥½æ‰£åˆ†ä¸­ç­‰
            if self.gesture_status != "æ— å°åŠ¨ä½œ":
                score -= 15  # æœ‰å°åŠ¨ä½œæ‰£åˆ†è¾ƒå°‘
        
        # æ·»åŠ éšæœºæ³¢åŠ¨ï¼Œä½¿åˆ†æ•°æ›´è‡ªç„¶
        import random
        score += random.uniform(-5, 5)
        
        # é™åˆ¶åˆ†æ•°èŒƒå›´
        self.attention_score = max(0, min(100, score))
    
    def _update_feedback(self):
        """æ›´æ–°è¯­éŸ³åé¦ˆ"""
        # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°é¢éƒ¨ï¼Œæé†’ç”¨æˆ·
        if not self.face_detected:
            self.voice.speak("è¯·è°ƒæ•´ä½ç½®ï¼Œç¡®ä¿é¢éƒ¨åœ¨æ‘„åƒå¤´èŒƒå›´å†…", urgent=True)
            return
        
        # æ ¹æ®è§†çº¿çŠ¶æ€æä¾›åé¦ˆ
        if self.gaze_status != "æ­£å¸¸":
            self.voice.give_gaze_feedback(urgent=True)
        
        # æ ¹æ®å§¿æ€çŠ¶æ€æä¾›åé¦ˆ
        if self.pose_status != "è‰¯å¥½":
            self.voice.give_pose_feedback(self.pose_status, urgent=True)
        
        # æ ¹æ®æ‰‹åŠ¿çŠ¶æ€æä¾›åé¦ˆ
        if self.gesture_status != "æ— å°åŠ¨ä½œ":
            self.voice.give_gesture_feedback(self.gesture_status, urgent=True)
        
        # å¦‚æœæ³¨æ„åŠ›åˆ†æ•°è¾ƒé«˜ï¼Œæä¾›é¼“åŠ±
        if self.attention_score >= 85 and self.frame_count % 300 == 0:  # æ¯10ç§’ä¸€æ¬¡
            self.voice.give_encouragement(urgent=False)
    
    def get_session_time(self):
        """è·å–ä¼šè¯æ—¶é—´"""
        if not self.start_time:
            return 0
        return (datetime.now() - self.start_time).total_seconds()
    
    def process_frame(self, frame):
        """å¤„ç†å•å¸§å›¾åƒï¼Œç”¨äºWeb API
        
        Args:
            frame: å›¾åƒå¸§
            
        Returns:
            æ£€æµ‹ç»“æœå­—å…¸
        """
        # æ›´æ–°æ£€æµ‹ç»“æœ
        self._update_detection(frame)
        
        # è¿”å›æ£€æµ‹ç»“æœ
        return {
            'attention_score': self.attention_score,
            'gaze_status': self.gaze_status,
            'pose_status': self.pose_status,
            'gesture_status': self.gesture_status,
            'face_detected': self.face_detected,
            'gaze_away_count': self.gaze_away_count,
            'pose_issue_count': self.pose_issue_count,
            'gesture_count': self.gesture_count,
            'session_time': self.get_session_time()
        }
    
    def _reset_statistics(self):
        """é‡ç½®ç»Ÿè®¡æ•°æ®"""
        self.gaze_away_count = 0
        self.pose_issue_count = 0
        self.gesture_count = 0
        self.attention_score = 100.0  # åˆå§‹åˆ†æ•°è®¾ä¸ºæ»¡åˆ†
        print("Statistics have been reset")


def main():
    """ç¨‹åºå…¥å£"""
    print("=" * 60)
    print("Interview Coach - Attention Monitor v0.2")
    print("=" * 60)
    print("\nFeatures:")
    print("1. Real-time face detection and keypoint extraction")
    print("2. Gaze direction detection and reminder")
    print("3. Head posture analysis and feedback")
    print("4. Small gesture detection and prompts")
    print("5. Intelligent voice feedback system")
    print("\nCurrent Version: Integrated Detection (v0.2)")
    print("-" * 60)

    # åˆ›å»ºåŠ©æ‰‹å®ä¾‹
    coach = InterviewCoachV2()

    # è¿è¡Œä¸»ç¨‹åº
    try:
        coach.run()
    except KeyboardInterrupt:
        print("\nUser interrupted the program")
    except Exception as e:
        print(f"\nâŒ Program error: {e}")
        import traceback
        traceback.print_exc()

    print("\nThank you for using!")


if __name__ == "__main__":
    main()