# src/main.py - é¢è¯•åŠ©æ‰‹v0.2
import cv2
import pyttsx3
import numpy as np
import time
from datetime import datetime

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from camera_utils import CameraManager
from voice_utils import VoiceFeedback
from ui_manager import UIManager

# å¯¼å…¥æ£€æµ‹æ¨¡å—
try:
    from detection.face_detector import FaceDetector
    from detection.gaze_detector import GazeDetector
    from detection.pose_detector import PoseDetector
    from detection.gesture_detector import GestureDetector
    DETECTION_MODULES_AVAILABLE = True
    print("âœ… æ£€æµ‹æ¨¡å—åŠ è½½æˆåŠŸ")
except ImportError as e:
    DETECTION_MODULES_AVAILABLE = False
    print(f"âš ï¸ æ£€æµ‹æ¨¡å—åŠ è½½å¤±è´¥: {e}")
    print("å°†ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿è¡Œ")

class InterviewCoachV2:
    """é¢è¯•åŠ©æ‰‹ - ç‰ˆæœ¬2.0ï¼ˆé›†æˆæ£€æµ‹åŠŸèƒ½ï¼‰"""

    def __init__(self, use_ui=True):
        # åˆå§‹åŒ–æ‘„åƒå¤´ç®¡ç†å™¨
        self.camera = CameraManager(camera_id=0, resolution=(640, 480), fps=30)
        
        # åˆå§‹åŒ–è¯­éŸ³åé¦ˆç³»ç»Ÿ
        self.voice = VoiceFeedback(rate=160, volume=0.8)
        # ä¿å­˜è¯­éŸ³å¼•æ“çš„å¼•ç”¨ï¼Œæ–¹ä¾¿ç›´æ¥ä½¿ç”¨
        self.engine = self.voice.engine
        
        # åˆå§‹åŒ–UIç®¡ç†å™¨ - ä»…åœ¨éWebç¯å¢ƒä¸‹ä½¿ç”¨
        self.ui = None
        if use_ui:
            # åˆå§‹åŒ–UIç®¡ç†å™¨ - çª—å£å°ºå¯¸ä¸æ‘„åƒå¤´åˆ†è¾¨ç‡åŒ¹é…
            self.ui = UIManager(window_name="Interview Coach", window_size=(640, 480))
        
        # åˆå§‹åŒ–æ£€æµ‹å™¨ï¼ˆå¦‚æœæ¨¡å—å¯ç”¨ï¼‰
        self.detection_enabled = DETECTION_MODULES_AVAILABLE
        if self.detection_enabled:
            self.face_detector = FaceDetector()
            self.gaze_detector = GazeDetector()
            self.pose_detector = PoseDetector()
            self.gesture_detector = GestureDetector()
            print("âœ… æ‰€æœ‰æ£€æµ‹å™¨å·²åˆå§‹åŒ–")
        else:
            print("âš ï¸ æ£€æµ‹å™¨ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")

        # çŠ¶æ€å˜é‡
        self.is_running = False
        self.start_time = None
        self.frame_count = 0
        self.last_speak_time = 0
        
        # æ£€æµ‹çŠ¶æ€
        self.face_detected = False
        self.gaze_status = "æ­£å¸¸"
        self.pose_status = "æ­£å¸¸"
        self.gesture_status = "æ— "
        self.attention_score = 100.0  # åˆå§‹åˆ†æ•°è®¾ä¸ºæ»¡åˆ†
        
        # ç»Ÿè®¡æ•°æ®
        self.gaze_away_count = 0
        self.pose_issue_count = 0
        self.gesture_count = 0
        
        # æ³¨æ„åŠ›å†å²è®°å½•
        self.attention_history = []

        print("âœ… é¢è¯•åŠ©æ‰‹v2.0å·²åˆå§‹åŒ–")
        print("Tips: Press 's' to start/stop, 'q' to exit, 't' to test voice")

    def speak(self, text, urgent=False):
        """è¯­éŸ³è¾“å‡ºï¼ˆå¸¦å†·å´æ—¶é—´ï¼‰"""
        current_time = datetime.now().timestamp()

        # å†·å´æ—¶é—´ï¼šç´§æ€¥æç¤º2ç§’ï¼Œæ™®é€šæç¤º4ç§’
        cooldown = 2.0 if urgent else 4.0

        if current_time - self.last_speak_time > cooldown:
            print(f"ğŸ”Š è¯­éŸ³æç¤º: {text}")
            self.engine.say(text)
            self.engine.runAndWait()
            self.last_speak_time = current_time
            return True
        return False

    def draw_ui(self, frame):
        """ç»˜åˆ¶UIç•Œé¢
        
        Args:
            frame: è§†é¢‘å¸§
            
        Returns:
            å¸¦UIçš„è§†é¢‘å¸§
        """
        # å¦‚æœUIæœªåˆå§‹åŒ–ï¼Œç›´æ¥è¿”å›åŸå§‹å¸§
        if not self.ui:
            return frame
            
        # ç»˜åˆ¶é¡¶éƒ¨çŠ¶æ€æ 
        frame = self.ui.draw_top_bar(frame)
        
        # ç»˜åˆ¶å³ä¾§ä¿¡æ¯é¢æ¿
        status_info = {
            'status': 'æ­£å¸¸' if self.attention_score >= 70 else 'æ³¨æ„åŠ›ä¸é›†ä¸­',
            'attention_score': int(self.attention_score),
            'gaze_direction': self.gaze_status,
            'posture': self.pose_status,
            'gesture': self.gesture_status,
            'look_away_count': self.gaze_away_count,
            'bad_posture_count': self.pose_issue_count,
            'gesture_count': self.gesture_count
        }
        frame = self.ui.draw_side_panel(frame, status_info)
        
        # ç»˜åˆ¶åº•éƒ¨ä¿¡æ¯æ 
        feedback_text = self.voice.get_latest_feedback() or "ç³»ç»Ÿè¿è¡Œä¸­..."
        frame = self.ui.draw_bottom_bar(frame, feedback_text)
        
        # ç»˜åˆ¶æ³¨æ„åŠ›ä»ªè¡¨ç›˜
        frame = self.ui.draw_attention_meter(frame, self.attention_score)
        
        # å¦‚æœæ£€æµ‹åˆ°é¢éƒ¨ï¼Œç»˜åˆ¶å…³é”®ç‚¹å’Œè§†çº¿æ–¹å‘
        if self.face_detected and self.detection_enabled:
            # è·å–é¢éƒ¨å…³é”®ç‚¹
            has_face, landmarks, _ = self.face_detector.detect(frame)
            if has_face and landmarks:
                frame = self.ui.draw_face_landmarks(frame, landmarks)
            
            # è·å–è§†çº¿æ£€æµ‹ç»“æœ
            is_looking, offset_ratio, annotated_frame = self.gaze_detector.detect_gaze(frame)
            if is_looking is not None:
                # ä½¿ç”¨å¸¦æ ‡æ³¨çš„å›¾åƒ
                frame = annotated_frame
        
        # æ·»åŠ æ—¶é—´æˆ³
        frame = self.ui.add_timestamp(frame)
        
        # å¦‚æœæ³¨æ„åŠ›åˆ†æ•°è¿‡ä½ï¼Œæ·»åŠ è­¦å‘Š
        if self.attention_score < 50:
            frame = self.ui.add_warning(frame, "æ³¨æ„åŠ›ä¸é›†ä¸­ï¼Œè¯·é›†ä¸­ç²¾ç¥ï¼")
        
        return frame

    def run(self):
        """ä¸»å¾ªç¯"""
        print("â–¶ï¸ Starting main loop...")
        
        # æ‰“å¼€æ‘„åƒå¤´
        if not self.camera.open():
            print("âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
            return
        
        # åˆ›å»ºUIçª—å£
        self.ui.create_window()
        
        # ä¸»å¾ªç¯
        while True:
            # è¯»å–æ‘„åƒå¤´å¸§
            ret, frame = self.camera.read_frame()
            if not ret:
                print("âŒ æ— æ³•è¯»å–æ‘„åƒå¤´ç”»é¢")
                break
            
            self.frame_count += 1
            
            # å¦‚æœæ­£åœ¨è¿è¡Œï¼Œè¿›è¡Œæ£€æµ‹å’Œæ›´æ–°
            if self.is_running:
                self._update_detection(frame)
                self._update_feedback()
            
            # è·å–ä¼šè¯æ—¶é—´å’ŒFPS
            session_time = 0
            fps = self.camera.fps_actual
            if self.start_time:
                session_time = (datetime.now() - self.start_time).total_seconds()
            
            # ç»˜åˆ¶UI
            frame = self.draw_ui(frame)
            
            # æ˜¾ç¤ºç”»é¢
            cv2.imshow(self.ui.window_name, frame)
            
            # é”®ç›˜ç›‘å¬
            key = cv2.waitKey(1) & 0xFF
            
            # 's'é”®ï¼šå¼€å§‹/åœæ­¢
            if key == ord('s'):
                self.is_running = not self.is_running
                if self.is_running:
                    self.start_time = datetime.now()
                    self._reset_statistics()
                    self.voice.start_session()
                    print("âºï¸ Started recording...")
                else:
                    self.voice.end_session()
                    print("â¹ï¸ Stopped recording")
            
            # 't'é”®ï¼šæµ‹è¯•è¯­éŸ³
            elif key == ord('t'):
                self.voice.test_voice()
            
            # 'q'é”®ï¼šé€€å‡º
            elif key == ord('q'):
                self.voice.end_session()
                break
        
        # æ¸…ç†èµ„æº
        self.camera.close()
        self.ui.destroy_window()
        print("ğŸ‘‹ Program exited")
    
    def _update_detection(self, frame):
        """æ›´æ–°æ£€æµ‹ç»“æœ
        
        Args:
            frame: å›¾åƒå¸§
        """
        if not self.detection_enabled:
            # æ¨¡æ‹Ÿæ£€æµ‹æ•°æ®
            self._simulate_detection()
            return
        
        # é¢éƒ¨æ£€æµ‹ - ç¦ç”¨ç»˜åˆ¶ä»¥æé«˜æ€§èƒ½
        has_face, landmarks, _ = self.face_detector.detect(frame, draw_annotations=False)
        self.face_detected = has_face
        
        # æ£€æŸ¥é¢éƒ¨æ£€æµ‹ç»“æœå’Œå…³é”®ç‚¹
        if not self.face_detected or landmarks is None:
            # æ²¡æœ‰æ£€æµ‹åˆ°é¢éƒ¨æˆ–å…³é”®ç‚¹æ— æ•ˆï¼Œé‡ç½®å…¶ä»–æ£€æµ‹çŠ¶æ€
            self.gaze_status = "æœªæ£€æµ‹åˆ°é¢éƒ¨"
            self.pose_status = "æœªæ£€æµ‹åˆ°é¢éƒ¨"
            self.gesture_status = "æœªæ£€æµ‹åˆ°é¢éƒ¨"
            self.attention_score = max(0, self.attention_score - 2)
            return
        
        try:
            # è§†çº¿æ£€æµ‹ï¼ˆéœ€è¦æœ‰æ•ˆçš„é¢éƒ¨å…³é”®ç‚¹ï¼‰- ç¦ç”¨ç»˜åˆ¶
            is_looking, offset_ratio, _ = self.gaze_detector.detect_gaze(frame, draw_annotations=False)
            self.gaze_status = self.gaze_detector.get_gaze_status_text(is_looking, offset_ratio)
            if self.gaze_status != "æ­£å¸¸":
                self.gaze_away_count += 1
        except Exception as e:
            print(f"è§†çº¿æ£€æµ‹å¤±è´¥: {e}")
            self.gaze_status = "æ£€æµ‹å¤±è´¥"
        
        try:
            # å§¿æ€æ£€æµ‹ - ç¦ç”¨ç»˜åˆ¶
            pose_status, pose_angle, _ = self.pose_detector.detect_pose(frame, draw_annotations=False)
            self.pose_status = self.pose_detector.get_pose_status_text(pose_status)
            if self.pose_status != "è‰¯å¥½":
                self.pose_issue_count += 1
        except Exception as e:
            print(f"å§¿æ€æ£€æµ‹å¤±è´¥: {e}")
            self.pose_status = "æ£€æµ‹å¤±è´¥"
        
        try:
            # æ‰‹åŠ¿æ£€æµ‹ - ç¦ç”¨ç»˜åˆ¶
            gesture_type, confidence, _ = self.gesture_detector.detect_gestures(frame, draw_annotations=False)
            self.gesture_status = self.gesture_detector.get_gesture_status_text(gesture_type, confidence)
            if self.gesture_status != "æ— å°åŠ¨ä½œ":
                self.gesture_count += 1
        except Exception as e:
            print(f"æ‰‹åŠ¿æ£€æµ‹å¤±è´¥: {e}")
            self.gesture_status = "æ£€æµ‹å¤±è´¥"
        
        # è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°
        self._calculate_attention_score()
    
    def _simulate_detection(self):
        """æ¨¡æ‹Ÿæ£€æµ‹ç»“æœï¼ˆå½“æ£€æµ‹æ¨¡å—ä¸å¯ç”¨æ—¶ï¼‰"""
        import random
        
        # åªåœ¨æ¯30å¸§æ›´æ–°ä¸€æ¬¡æ¨¡æ‹Ÿæ•°æ®ï¼ˆçº¦1ç§’æ›´æ–°ä¸€æ¬¡ï¼Œå‡è®¾30fpsï¼‰
        if self.frame_count % 30 != 0:
            return
        
        # æ¨¡æ‹Ÿé¢éƒ¨æ£€æµ‹ï¼ˆ95%æ¦‚ç‡æˆåŠŸï¼‰
        self.face_detected = random.random() < 0.95
        
        if not self.face_detected:
            self.gaze_status = "æœªæ£€æµ‹åˆ°é¢éƒ¨"
            self.pose_status = "æœªæ£€æµ‹åˆ°é¢éƒ¨"
            self.gesture_status = "æœªæ£€æµ‹åˆ°é¢éƒ¨"
            self.attention_score = max(0, self.attention_score - random.uniform(10, 20))
            return
        
        # æ¨¡æ‹Ÿè§†çº¿æ£€æµ‹ï¼ˆ80%æ¦‚ç‡æ­£å¸¸ï¼‰
        if random.random() < 0.8:
            self.gaze_status = "æ­£å¸¸"
        else:
            self.gaze_status = "è§†çº¿åç¦»"
            self.gaze_away_count += 1
        
        # æ¨¡æ‹Ÿå§¿æ€æ£€æµ‹ï¼ˆ85%æ¦‚ç‡æ­£å¸¸ï¼‰
        if random.random() < 0.85:
            self.pose_status = "è‰¯å¥½"
        else:
            self.pose_status = random.choice(["âš ï¸ è¯·å‹¿é¢‘ç¹æŠ¬å¤´", "âš ï¸ è¯·ä¿æŒæŠ¬å¤´æŒºèƒ¸", "âš ï¸ è¯·ä¿æŒå¤´éƒ¨æ­£ç›´", "âš ï¸ è¯·ä¿æŒé¢å‘æ‘„åƒå¤´"])
            self.pose_issue_count += 1
        
        # æ¨¡æ‹Ÿæ‰‹åŠ¿æ£€æµ‹ï¼ˆ90%æ¦‚ç‡æ— å°åŠ¨ä½œï¼‰
        if random.random() < 0.9:
            self.gesture_status = "æ— å°åŠ¨ä½œ"
        else:
            self.gesture_status = random.choice(["âš ï¸ è¯·é¿å…æ‘¸è„¸", "âš ï¸ è¯·é¿å…æ‘¸ä¸‹å·´", "âš ï¸ è¯·é¿å…æ‘¸å¤´å‘", "âš ï¸ è¯·é¿å…æ‰˜è…®"])
            self.gesture_count += 1
        
        # è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°
        self._calculate_attention_score()
    
    def _calculate_attention_score(self):
        """è®¡ç®—æ³¨æ„åŠ›åˆ†æ•° - é‡‡ç”¨åŠ æƒç»¼åˆè¯„åˆ†æœºåˆ¶"""
        # æƒé‡é…ç½®ï¼ˆå¯æ ¹æ®å®é™…éœ€æ±‚è°ƒæ•´ï¼‰
        weights = {
            'face_detection': 0.3,    # é¢éƒ¨æ£€æµ‹å 30%
            'gaze_direction': 0.35,    # è§†çº¿æ–¹å‘å 35%
            'posture': 0.2,            # å§¿æ€å 20%
            'gesture': 0.15            # æ‰‹åŠ¿å 15%
        }
        
        # åˆå§‹å„é¡¹å¾—åˆ†
        face_score = 100.0
        gaze_score = 100.0
        posture_score = 100.0
        gesture_score = 100.0
        
        # é¢éƒ¨æ£€æµ‹è¯„åˆ†
        if not self.face_detected:
            face_score = 0.0  # æœªæ£€æµ‹åˆ°é¢éƒ¨ç›´æ¥0åˆ†
        
        # è§†çº¿æ–¹å‘è¯„åˆ†
        if self.gaze_status == "æ­£å¸¸":
            gaze_score = 100.0
        elif self.gaze_status == "è½»å¾®åç§»":
            gaze_score = 70.0
        elif self.gaze_status == "æ˜æ˜¾åç§»":
            gaze_score = 40.0
        else:  # ä¸¥é‡åç§»æˆ–æ£€æµ‹å¤±è´¥
            gaze_score = 10.0
        
        # å§¿æ€è¯„åˆ†
        if self.pose_status == "è‰¯å¥½":
            posture_score = 100.0
        elif "æŠ¬å¤´" in self.pose_status:
            posture_score = 75.0
        elif "ä½å¤´" in self.pose_status:
            posture_score = 70.0
        elif "æ­ªå¤´" in self.pose_status:
            posture_score = 65.0
        elif "è½¬å¤´" in self.pose_status:
            posture_score = 60.0
        else:  # æ£€æµ‹å¤±è´¥
            posture_score = 50.0
        
        # æ‰‹åŠ¿è¯„åˆ†
        if self.gesture_status == "æ— å°åŠ¨ä½œ":
            gesture_score = 100.0
        else:  # æœ‰å°åŠ¨ä½œ
            gesture_score = 70.0
        
        # è®¡ç®—åŠ æƒç»¼åˆå¾—åˆ†
        weighted_score = (
            face_score * weights['face_detection'] +
            gaze_score * weights['gaze_direction'] +
            posture_score * weights['posture'] +
            gesture_score * weights['gesture']
        )
        
        # æ—¶é—´è¡°å‡å› å­ï¼ˆæŒç»­æ³¨æ„åŠ›å¥–åŠ±ï¼‰
        # å¦‚æœæ³¨æ„åŠ›æŒç»­è‰¯å¥½ï¼Œåˆ†æ•°ä¼šç¼“æ…¢ä¸Šå‡
        session_time = self.get_session_time()
        if session_time > 0:
            # æ¯10ç§’å¢åŠ 1åˆ†ï¼Œæœ€å¤šå¢åŠ 10åˆ†
            time_bonus = min(10.0, session_time / 10.0)
            weighted_score = min(100.0, weighted_score + time_bonus)
        
        # å¹³æ»‘åˆ†æ•°å˜åŒ–ï¼ˆé¿å…çªç„¶è·³å˜ï¼‰
        alpha = 0.8  # å¹³æ»‘ç³»æ•°ï¼Œ0-1ä¹‹é—´ï¼Œè¶Šå¤§è¶Šå¹³æ»‘
        self.attention_score = alpha * self.attention_score + (1 - alpha) * weighted_score
        
        # é™åˆ¶åˆ†æ•°èŒƒå›´
        self.attention_score = max(0, min(100, self.attention_score))
        
        # è®°å½•å†å²åˆ†æ•°ï¼ˆç”¨äºæ•°æ®åˆ†æï¼‰
        current_time = datetime.now().timestamp()
        if not hasattr(self, 'attention_history'):
            self.attention_history = []
        self.attention_history.append({
            'timestamp': current_time,
            'score': self.attention_score,
            'face_score': face_score,
            'gaze_score': gaze_score,
            'posture_score': posture_score,
            'gesture_score': gesture_score
        })
        
        # é™åˆ¶å†å²è®°å½•é•¿åº¦ï¼ˆæœ€å¤šä¿å­˜1000æ¡ï¼‰
        if len(self.attention_history) > 1000:
            self.attention_history.pop(0)
    
    def _update_feedback(self):
        """æ›´æ–°è¯­éŸ³åé¦ˆ"""
        # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°é¢éƒ¨ï¼Œæé†’ç”¨æˆ·
        if not self.face_detected:
            self.voice.speak("è¯·è°ƒæ•´ä½ç½®ï¼Œç¡®ä¿é¢éƒ¨åœ¨æ‘„åƒå¤´èŒƒå›´å†…", urgent=True)
            return
        
        # æ ¹æ®è§†çº¿çŠ¶æ€æä¾›åé¦ˆ
        if self.gaze_status != "æ­£å¸¸":
            self.voice.give_gaze_feedback(urgent=True)
        
        # æ ¹æ®å§¿æ€çŠ¶æ€æä¾›åé¦ˆ
        if self.pose_status != "è‰¯å¥½":
            self.voice.give_pose_feedback(self.pose_status, urgent=True)
        
        # æ ¹æ®æ‰‹åŠ¿çŠ¶æ€æä¾›åé¦ˆ
        if self.gesture_status != "æ— å°åŠ¨ä½œ":
            self.voice.give_gesture_feedback(self.gesture_status, urgent=True)
        
        # å¦‚æœæ³¨æ„åŠ›åˆ†æ•°è¾ƒé«˜ï¼Œæä¾›é¼“åŠ±
        if self.attention_score >= 85 and self.frame_count % 300 == 0:  # æ¯10ç§’ä¸€æ¬¡
            self.voice.give_encouragement(urgent=False)
    
    def get_session_time(self):
        """è·å–ä¼šè¯æ—¶é—´"""
        if not self.start_time:
            return 0
        return (datetime.now() - self.start_time).total_seconds()
    
    def process_frame(self, frame):
        """å¤„ç†å•å¸§å›¾åƒï¼Œç”¨äºWeb API
        
        Args:
            frame: å›¾åƒå¸§
            
        Returns:
            æ£€æµ‹ç»“æœå­—å…¸
        """
        # æ›´æ–°æ£€æµ‹ç»“æœ
        self._update_detection(frame)
        
        # è¿”å›æ£€æµ‹ç»“æœ
        return {
            'attention_score': self.attention_score,
            'gaze_status': self.gaze_status,
            'pose_status': self.pose_status,
            'gesture_status': self.gesture_status,
            'face_detected': self.face_detected,
            'gaze_away_count': self.gaze_away_count,
            'pose_issue_count': self.pose_issue_count,
            'gesture_count': self.gesture_count,
            'session_time': self.get_session_time()
        }
    
    def _reset_statistics(self):
        """é‡ç½®ç»Ÿè®¡æ•°æ®"""
        self.gaze_away_count = 0
        self.pose_issue_count = 0
        self.gesture_count = 0
        self.attention_score = 100.0  # åˆå§‹åˆ†æ•°è®¾ä¸ºæ»¡åˆ†
        self.attention_history = []  # é‡ç½®å†å²è®°å½•
        self.attention_states = {
            'high': 0,  # é«˜åº¦é›†ä¸­ï¼ˆ85-100åˆ†ï¼‰
            'medium': 0,  # ä¸­ç­‰é›†ä¸­ï¼ˆ60-84åˆ†ï¼‰
            'low': 0,  # æ³¨æ„åŠ›åˆ†æ•£ï¼ˆ0-59åˆ†ï¼‰
            'face_missing': 0  # æœªæ£€æµ‹åˆ°é¢éƒ¨
        }
        print("Statistics have been reset")
    
    def save_final_state(self):
        """ä¿å­˜æœ€ç»ˆçŠ¶æ€ï¼Œç¡®ä¿æ‰€æœ‰æ•°æ®éƒ½å·²æ­£ç¡®å¤„ç†"""
        try:
            # ç¡®ä¿æ³¨æ„åŠ›å†å²è®°å½•å·²åˆå§‹åŒ–
            if not hasattr(self, 'attention_history'):
                self.attention_history = []
            
            # æ‰“å°æœ€ç»ˆçŠ¶æ€æ‘˜è¦
            print(f"ğŸ“Š ä¿å­˜æœ€ç»ˆçŠ¶æ€: ")
            print(f"   - æ€»è®°å½•æ•°: {len(self.attention_history)}")
            print(f"   - è§†çº¿ç¦»å¼€æ¬¡æ•°: {self.gaze_away_count}")
            print(f"   - å§¿æ€é—®é¢˜æ¬¡æ•°: {self.pose_issue_count}")
            print(f"   - æ‰‹åŠ¿æ¬¡æ•°: {self.gesture_count}")
            print(f"   - é¢è¯•æ—¶é•¿: {self.get_session_time()}ç§’")
            
        except Exception as e:
            print(f"âŒ ä¿å­˜æœ€ç»ˆçŠ¶æ€æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
    
    def get_attention_analysis(self):
        """è·å–æ³¨æ„åŠ›åˆ†ææŠ¥å‘Š"""
        print(f"ğŸ“Š get_attention_analysis è¢«è°ƒç”¨")
        print(f"   - attention_history å­˜åœ¨: {hasattr(self, 'attention_history')}")
        if hasattr(self, 'attention_history'):
            print(f"   - attention_history é•¿åº¦: {len(self.attention_history)}")
        
        # åˆå§‹åŒ–æ³¨æ„åŠ›çŠ¶æ€åˆ†å¸ƒ
        attention_states = {
            'high': 0,  # é«˜åº¦é›†ä¸­ï¼ˆ85-100åˆ†ï¼‰
            'medium': 0,  # ä¸­ç­‰é›†ä¸­ï¼ˆ60-84åˆ†ï¼‰
            'low': 0,  # æ³¨æ„åŠ›åˆ†æ•£ï¼ˆ0-59åˆ†ï¼‰
            'face_missing': 0  # æœªæ£€æµ‹åˆ°é¢éƒ¨
        }
        
        # åˆå§‹åŒ–ç»Ÿè®¡æ•°æ®
        total_records = 0
        avg_face = 0
        avg_gaze = 0
        avg_posture = 0
        avg_gesture = 0
        final_attention_score = self.attention_score
        
        # ç»Ÿè®¡æ³¨æ„åŠ›çŠ¶æ€åˆ†å¸ƒå’Œè®¡ç®—å¹³å‡å€¼
        if hasattr(self, 'attention_history') and self.attention_history:
            attention_history = self.attention_history
            total_records = len(attention_history)
            print(f"   - å¤„ç† {total_records} æ¡è®°å½•")
            
            # ç»Ÿè®¡æ³¨æ„åŠ›çŠ¶æ€
            for record in attention_history:
                score = record['score']
                if score >= 85:
                    attention_states['high'] += 1
                elif score >= 60:
                    attention_states['medium'] += 1
                else:
                    attention_states['low'] += 1
                
                # ç»Ÿè®¡æœªæ£€æµ‹åˆ°é¢éƒ¨çš„æƒ…å†µ
                if record['face_score'] == 0:
                    attention_states['face_missing'] += 1
            
            # è®¡ç®—å„é¡¹å¹³å‡åˆ†
            face_scores = [record['face_score'] for record in attention_history]
            gaze_scores = [record['gaze_score'] for record in attention_history]
            posture_scores = [record['posture_score'] for record in attention_history]
            gesture_scores = [record['gesture_score'] for record in attention_history]
            
            # é¿å…é™¤ä»¥é›¶çš„å¼‚å¸¸
            avg_face = sum(face_scores) / len(face_scores) if len(face_scores) > 0 else 0
            avg_gaze = sum(gaze_scores) / len(gaze_scores) if len(gaze_scores) > 0 else 0
            avg_posture = sum(posture_scores) / len(posture_scores) if len(posture_scores) > 0 else 0
            avg_gesture = sum(gesture_scores) / len(gesture_scores) if len(gesture_scores) > 0 else 0
            
            # é‡æ–°è®¡ç®—æœ€ç»ˆæ³¨æ„åŠ›åˆ†æ•°ï¼ˆåŸºäºæ‰€æœ‰æ•°æ®çš„å¹³å‡åˆ†ï¼‰
            final_attention_score = sum([record['score'] for record in attention_history]) / len(attention_history) if len(attention_history) > 0 else self.attention_score
        else:
            print(f"   - æ²¡æœ‰å†å²è®°å½•ï¼Œä½¿ç”¨é»˜è®¤æ•°æ®")
        
        # ç”Ÿæˆæ”¹è¿›å»ºè®®
        recommendations = []
        
        # æ ¹æ®å„é¡¹å¹³å‡åˆ†æ•°ç”Ÿæˆé’ˆå¯¹æ€§å»ºè®®
        if total_records > 0:
            # åŸºäºå¹³å‡åˆ†ç”Ÿæˆå…·ä½“å»ºè®®
            if avg_face < 80:
                recommendations.append("è¯·ç¡®ä¿é¢éƒ¨å§‹ç»ˆåœ¨æ‘„åƒå¤´èŒƒå›´å†…ï¼Œé¿å…é¢‘ç¹ç¦»å¼€ç”»é¢ã€‚å»ºè®®è°ƒæ•´æ‘„åƒå¤´ä½ç½®ï¼Œä½¿é¢éƒ¨ä¿æŒåœ¨ç”»é¢ä¸­å¤®ã€‚")
            if avg_gaze < 70:
                recommendations.append("è¯·æ³¨æ„ä¿æŒè§†çº¿é›†ä¸­åœ¨æ‘„åƒå¤´æ–¹å‘ï¼Œé¿å…é¢‘ç¹çœ‹å‘å…¶ä»–åœ°æ–¹ã€‚è¿™æœ‰åŠ©äºå±•ç°æ‚¨çš„ä¸“æ³¨æ€åº¦ã€‚")
            if avg_posture < 70:
                recommendations.append("è¯·ä¿æŒè‰¯å¥½çš„åå§¿ï¼Œé¿å…ä½å¤´ã€æŠ¬å¤´æˆ–æ­ªå¤´ã€‚ä¿æŒèƒŒéƒ¨æŒºç›´ï¼Œæœ‰åŠ©äºå±•ç°è‡ªä¿¡å½¢è±¡ã€‚")
            if avg_gesture < 80:
                recommendations.append("è¯·å°½é‡å‡å°‘ä¸å¿…è¦çš„æ‰‹éƒ¨åŠ¨ä½œï¼Œä¿æŒä¸“ä¸šå§¿æ€ã€‚é€‚å½“çš„æ‰‹åŠ¿å¯ä»¥å¢å¼ºè¡¨è¾¾ï¼Œä½†è¿‡åº¦çš„åŠ¨ä½œä¼šåˆ†æ•£æ³¨æ„åŠ›ã€‚")
            
            # åŸºäºæ³¨æ„åŠ›çŠ¶æ€åˆ†å¸ƒç”Ÿæˆå»ºè®®
            high_ratio = attention_states['high'] / total_records if total_records > 0 else 0
            low_ratio = attention_states['low'] / total_records if total_records > 0 else 0
            
            if high_ratio > 0.7:
                recommendations.append("æ‚¨åœ¨é¢è¯•è¿‡ç¨‹ä¸­è¡¨ç°å‡ºé«˜åº¦çš„æ³¨æ„åŠ›é›†ä¸­ï¼Œç»§ç»­ä¿æŒè¿™ç§è‰¯å¥½çŠ¶æ€ï¼")
            elif low_ratio > 0.3:
                recommendations.append("æ‚¨åœ¨é¢è¯•è¿‡ç¨‹ä¸­æ³¨æ„åŠ›åˆ†æ•£çš„æ—¶é—´è¾ƒå¤šï¼Œå»ºè®®æå‰åšå¥½å‡†å¤‡ï¼Œå‡å°‘å¤–ç•Œå¹²æ‰°ã€‚")
        
        # å¦‚æœæ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®ï¼Œæä¾›é€šç”¨å»ºè®®
        if not recommendations:
            recommendations = [
                "ä¿æŒé¢éƒ¨åœ¨æ‘„åƒå¤´èŒƒå›´å†…ï¼Œç¡®ä¿æ¸…æ™°å¯è§",
                "ä¿æŒè§†çº¿é›†ä¸­åœ¨æ‘„åƒå¤´æ–¹å‘ï¼Œå±•ç°ä¸“æ³¨æ€åº¦",
                "ä¿æŒè‰¯å¥½çš„åå§¿ï¼ŒæŠ¬å¤´æŒºèƒ¸ï¼Œå±•ç°è‡ªä¿¡",
                "å‡å°‘ä¸å¿…è¦çš„æ‰‹éƒ¨åŠ¨ä½œï¼Œä¿æŒä¸“ä¸šå½¢è±¡"
            ]
        
        # ç”Ÿæˆè¯„åˆ†ä¾æ®
        scoring_criteria = {
            'face_detection': {
                'weight': 0.3,
                'description': "é¢éƒ¨æ£€æµ‹ - ä¿æŒé¢éƒ¨åœ¨æ‘„åƒå¤´èŒƒå›´å†…",
                'current_status': "æ£€æµ‹åˆ°é¢éƒ¨" if self.face_detected else "æœªæ£€æµ‹åˆ°é¢éƒ¨",
                'average_score': round(avg_face, 2)
            },
            'gaze_direction': {
                'weight': 0.35,
                'description': "è§†çº¿æ–¹å‘ - ä¿æŒè§†çº¿é›†ä¸­åœ¨æ‘„åƒå¤´",
                'current_status': self.gaze_status,
                'average_score': round(avg_gaze, 2)
            },
            'posture': {
                'weight': 0.2,
                'description': "å§¿æ€ - ä¿æŒè‰¯å¥½çš„åå§¿",
                'current_status': self.pose_status,
                'average_score': round(avg_posture, 2)
            },
            'gesture': {
                'weight': 0.15,
                'description': "æ‰‹åŠ¿ - å‡å°‘ä¸å¿…è¦çš„åŠ¨ä½œ",
                'current_status': self.gesture_status,
                'average_score': round(avg_gesture, 2)
            }
        }
        
        # ç”Ÿæˆè¯¦ç»†çš„ç»Ÿè®¡æ•°æ®
        statistics = {
            'gaze_away_count': self.gaze_away_count,
            'pose_issue_count': self.pose_issue_count,
            'gesture_count': self.gesture_count,
            'session_time': self.get_session_time(),
            'total_records': total_records,
            'attention_state_ratios': {
                'high': round(attention_states['high'] / total_records * 100, 1) if total_records > 0 else 0,
                'medium': round(attention_states['medium'] / total_records * 100, 1) if total_records > 0 else 0,
                'low': round(attention_states['low'] / total_records * 100, 1) if total_records > 0 else 0,
                'face_missing': round(attention_states['face_missing'] / total_records * 100, 1) if total_records > 0 else 0
            }
        }
        
        # ç”Ÿæˆé¢è¯•æ€»ç»“
        interview_summary = ""
        if total_records > 0:
            # è®¡ç®—æ³¨æ„åŠ›é›†ä¸­ç¨‹åº¦
            if final_attention_score >= 85:
                attention_level = "ä¼˜ç§€"
            elif final_attention_score >= 60:
                attention_level = "è‰¯å¥½"
            else:
                attention_level = "éœ€è¦æ”¹è¿›"
            
            # ç”Ÿæˆæ€»ç»“
            interview_summary = f"æ‚¨çš„é¢è¯•æ³¨æ„åŠ›è¡¨ç°{attention_level}ï¼Œæœ€ç»ˆå¾—åˆ†ä¸º{round(final_attention_score, 1)}åˆ†ã€‚"\
                               f"åœ¨é¢è¯•è¿‡ç¨‹ä¸­ï¼Œæ‚¨é«˜åº¦é›†ä¸­æ³¨æ„åŠ›çš„æ—¶é—´å æ¯”{statistics['attention_state_ratios']['high']}%ï¼Œ"\
                               f"ä¸­ç­‰é›†ä¸­çš„æ—¶é—´å æ¯”{statistics['attention_state_ratios']['medium']}%ï¼Œ"\
                               f"æ³¨æ„åŠ›åˆ†æ•£çš„æ—¶é—´å æ¯”{statistics['attention_state_ratios']['low']}%ã€‚"\
                               f"å»ºè®®æ‚¨é‡ç‚¹å…³æ³¨{', '.join([crit['description'].split(' - ')[0] for crit in scoring_criteria.values() if crit['average_score'] < 70])}æ–¹é¢çš„æ”¹è¿›ã€‚"
        else:
            interview_summary = "ç”±äºé¢è¯•æ—¶é—´è¾ƒçŸ­æˆ–æ•°æ®ä¸è¶³ï¼Œæ— æ³•ç”Ÿæˆè¯¦ç»†çš„æ³¨æ„åŠ›åˆ†ææŠ¥å‘Šã€‚å»ºè®®æ‚¨å»¶é•¿é¢è¯•æ—¶é—´ä»¥è·å¾—æ›´å‡†ç¡®çš„åˆ†æç»“æœã€‚"
        
        return {
            'attention_score': round(final_attention_score, 2),
            'attention_states': attention_states,
            'scoring_criteria': scoring_criteria,
            'recommendations': recommendations,
            'statistics': statistics,
            'interview_summary': interview_summary,
            'status': 'success' if total_records > 0 else 'insufficient_data',
            'message': 'æˆåŠŸç”Ÿæˆæ³¨æ„åŠ›åˆ†ææŠ¥å‘Š' if total_records > 0 else 'æ•°æ®ä¸è¶³ï¼Œç”ŸæˆåŸºç¡€åˆ†ææŠ¥å‘Š'
        }


def main():
    """ç¨‹åºå…¥å£"""
    print("=" * 60)
    print("Interview Coach - Attention Monitor v0.2")
    print("=" * 60)
    print("\nFeatures:")
    print("1. Real-time face detection and keypoint extraction")
    print("2. Gaze direction detection and reminder")
    print("3. Head posture analysis and feedback")
    print("4. Small gesture detection and prompts")
    print("5. Intelligent voice feedback system")
    print("\nCurrent Version: Integrated Detection (v0.2)")
    print("-" * 60)

    # åˆ›å»ºåŠ©æ‰‹å®ä¾‹
    coach = InterviewCoachV2()

    # è¿è¡Œä¸»ç¨‹åº
    try:
        coach.run()
    except KeyboardInterrupt:
        print("\nUser interrupted the program")
    except Exception as e:
        print(f"\nâŒ Program error: {e}")
        import traceback
        traceback.print_exc()

    print("\nThank you for using!")


if __name__ == "__main__":
    main()